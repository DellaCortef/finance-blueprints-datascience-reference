{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035519c4",
   "metadata": {},
   "source": [
    "# Supervised Learning: Regression\n",
    "\n",
    "Regression-based machine learning is a predictive form of modeling in which the goal is to model the relationship between a target and predictor variable(s) in order to estimate a continuous set of possible outcomes. It is the most widely used machine learning model in finance.\n",
    "\n",
    "One of the areas of focus for analysts in financial institutions (and finance in general) is predicting investment opportunities, typically by predicting asset prices and returns. Regression-based machine learning models are inherently well-suited in this context. They help financial and investment managers understand the properties of the predicted variable and its relationship to other variables, and also help them identify significant factors that drive asset returns. This helps investors estimate return profiles, trading costs, technical and financial infrastructure investments required, and consequently the risk profile and profitability of a strategy or portfolio.\n",
    "\n",
    "With the availability of large amounts of data and processing techniques, regression-based machine learning is not limited to asset price prediction. These models are applied to a wide range of areas within finance, including portfolio management, insurance and instrument pricing, hedging, and risk management.\n",
    "\n",
    "We will cover three areas of finance with the case studies, namely asset price prediction, instrument pricing, and portfolio management. All the case studies follow the seven-step process development model presented above; these steps include:\n",
    "1. defining the problem;\n",
    "2. loading the data;\n",
    "3. performing exploratory analysis;\n",
    "4. data preparation;\n",
    "5. model evaluation;\n",
    "6. feature engineering;\n",
    "7. model tuning.\n",
    "\n",
    "A substantial number of asset modeling and prediction problems in the financial industry involve a time component and the estimation of a continuous output. As such, it is also important to address *time series models*. In its broadest form, time series analysis is about inferring what happened to a series of data points in the past and trying to predict what will happen to them in the future. There has been much comparison and debate in academia and industry regarding the differences between supervised regression and time series models. Most time series models are *parametric* (i.e., a known function is assumed to represent the data), while most supervised regression models are *nonparametric*. Time series models primarily use historical data for the predicted variables for prediction, and supervised learning algorithms use *exogenous variables* as predictor variables. However, supervised regression can incorporate historical data of the predicted variable through a time delay approach, and a time series model (such as ARIMAX) can use exogenous variables for prediction. Thus, time series and supervised regression models are similar in that they can both use exogenous variables as well as historical data of the predicted variable to make predictions. Regarding the final output, both estimate a continuous set of possible outputs of a variable.\n",
    "\n",
    "Since time series models are more closely aligned with supervised regression than with supervised classification, we will cover the concepts of time series models here, but separately. We will also demonstrate how we can use time series models with financial data to predict future values. Additionally, some deep learning models (such as LSTM) can be used directly for time series forecasting.\n",
    "\n",
    "In “Case Study 1: Stock Price Prediction,” we will demonstrate one of the most common forecasting problems in finance: predicting stock returns. In addition to accurately predicting future stock prices, the purpose of this case study is to examine a machine learning-based framework for predicting a general asset class in finance. In it, we will explore several machine learning and time series concepts, and also focus on visualization and model tuning.\n",
    "\n",
    "In “Case Study 2: Derivatives Pricing,” we will dive into derivatives pricing using supervised regression and show how machine learning techniques can be applied to traditional quantitative analysis problems. When compared to traditional derivatives pricing models, machine learning techniques can lead to faster pricing without relying on a lot of useless assumptions. Efficient numerical computation using machine learning could be increasingly useful in areas such as financial risk management, where a trade-off between efficiency and accuracy is often unavoidable.\n",
    "\n",
    "In \"Case Study 3: Investor Risk Tolerance and Robo Advisors\", we will illustrate the supervised regression-based framework for estimating investor risk tolerance. In the case study, we will develop a robo advisor dashboard in Python and implement the risk tolerance prediction model in the dashboard. We will demonstrate how such models can lead to the automation of portfolio management processes, including the use of robo advisors for investment management. The purpose is to illustrate how machine learning can effectively be used to overcome the problem of traditional risk tolerance or risk tolerance questionnaires that suffer from several behavioral biases.\n",
    "\n",
    "In \"Case Study 4: Forward Curve Forecasting\", we will use a supervised regression-based framework to forecast the terms of the forward curves simultaneously. We will demonstrate how we can produce different terms at the same time to model the yield curve using machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "What we will do next\n",
    "\n",
    "- applying and comparing different time series and machine learning models;\n",
    "- interpreting the models and results. Understanding the potential for overfitting and underfitting and the intuition behind linear versus nonlinear models;\n",
    "- preparing and transforming data to be used in machine learning models;\n",
    "- selecting and engineering features to improve model performance;\n",
    "- using data visualization and exploration to understand the outputs;\n",
    "- tuning algorithms to improve model performance. Understanding, implementing, and tuning time series models, such as ARIMA, for forecasting;\n",
    "- structuring a problem statement related to portfolio management and behavioral finance in a regression-based machine learning framework;\n",
    "- understanding how deep learning-based models, such as LSTM, can be used for time series forecasting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387e2c1",
   "metadata": {},
   "source": [
    "## Time Series Models\n",
    "\n",
    "A *time series* is a sequence of numbers that are ordered by a time index. Let's look at the following aspects of time series models, which we will delve into later in the case studies:\n",
    "\n",
    "- the components of a time series;\n",
    "- the autocorrelation and stationarity of time series;\n",
    "- traditional time series models (such as ARIMA);\n",
    "- the use of deep learning models for time series modeling;\n",
    "- the conversion of time series data into a supervised learning framework.\n",
    "\n",
    "### The Parts of a Time Series\n",
    "\n",
    "A time series can be divided into the following components:\n",
    "\n",
    "*Trend Component*\n",
    "- a trend is a consistent directional movement in a time series. These trends will either be *deterministic* or *stochastic*. The former allows us to provide an underlying rationale for the trend, while the latter is a random feature of a series that we are unlikely to be able to explain. Trends commonly appear in financial series, and many trend models use sophisticated trend-identification algorithms.\n",
    "\n",
    "*Seasonal Component*\n",
    "- Many time series contain seasonal variation. This is especially true for time series that represent business sales or weather levels. In quantitative finance, we often see seasonal variation, especially in series related to the holiday season or annual temperature variation (such as natural gas).\n",
    "\n",
    "We can write the components of a time series $y_t$ as:\n",
    "\n",
    "$y_t = S_t + T_t + R_t$\n",
    "\n",
    "where $S_t$ is the seasonal component, $T_t$ is the trend component, and $R_t$ represents the remaining component of the time series that was not captured by the other two components.\n",
    "\n",
    "##### Implementation\n",
    "\n",
    "```Python\n",
    "import statsmodels.api as sm\n",
    "sm.tsa.seasonal_decompose(y, freq = 52).plot()\n",
    "```\n",
    "\n",
    "### Autocorrelation and Stationarity\n",
    "\n",
    "When we are given one or more time series, it is relatively straightforward to decompose them into trend, seasonality, and residual components. However, there are other aspects that come into play when working with time series data, especially in finance.\n",
    "\n",
    "#### Autocorrelation\n",
    "\n",
    "There are several situations in which consecutive elements of a time series exhibit correlation. That is, the behavior of sequential points in the series affects one another in a dependent manner. *Autocorrelation* is the similarity between observations as a function of the interval between them. Such relationships can be modeled using an autoregression model. The term *autoregression* indicates that it is a regression of the variable itself.\n",
    "\n",
    "In the autoregression model, we predict the variable of interest using a linear combination of past values ​​of the variable.\n",
    "\n",
    "Thus, an autoregressive model of order *p* can be written as:\n",
    "\n",
    "$y_t = c + \\phi_1 y_t-1 + \\phi_2 y_t-2 + ... + \\phi_p y_{t-p} + \\epsilon$\n",
    "\n",
    "where $\\epsilon_t$ is noise. An autoregressive model is like a multiple regression, but with values ​​with intervals of $y_t$ as predictors. We refer to this as the AR*(p)* model, an autoregressive model of order *p*. Autoregressive models are extremely flexible in handling a wide range of different time series patterns.\n",
    "\n",
    "#### Stationarity\n",
    "\n",
    "A time series is considered stationary if its statistical properties do not change over time. Therefore, a time series with a trend or seasonality is not stationary, since they will affect the value of the series at different times. On the other hand, a noise series is stationary, since it does not matter when you observe it, as it will be similar at any time.\n",
    "\n",
    "The figure below shows some examples of stationary and non-stationary series.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--pJUAANRS--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://miro.medium.com/max/1147/1%2Am0E2_nOE1oFhMc1L01oKsg.png\" width=\"600\">\n",
    "    <figcaption>Stationary and Non-stationary graphs</figcaption>\n",
    "</figure>\n",
    "\n",
    "In the second graph, we can clearly see that the mean is changing (increasing) over time, resulting in an upward trend. Thus, it is a non-stationary series. For a series to be classified as stationary, it should not exhibit a trend. Moving on to the third graph, we certainly do not see a trend in the series; its variance is a function of time. A stationary series should have constant variance; therefore, this series is also non-stationary. In the last graph, the distribution gets closer as time increases, suggesting that the covariance is a function of time. \n",
    "\n",
    "Looking at the first graph, the mean, variance, and covariance are constant over time. This is what a stationary time series looks like. Predicting future values using this graph would be easier. Most statistical models require the series to be stationary in order to make effective and accurate predictions.\n",
    "\n",
    "The two main reasons behind the non-stationarity of a time series are trend and seasonality. To use time series forecasting models, we typically convert any non-stationary series to stationary, which makes modeling easier since the statistical properties do not change over time.\n",
    "\n",
    "#### Differentiation\n",
    "\n",
    "Differentiation is one of the methods used to transform a time series into a stationary series. In this method, we compute the difference of consecutive terms in the series. Differentiation is typically performed to get rid of the varying mean. Mathematically, it can be expressed as:\n",
    "\n",
    "$y_t = y_t - y_{t-1}$\n",
    "\n",
    "where $y_t$ is the value at time *t*.\n",
    "\n",
    "When the differenced series is noise, the original series is referred to as a non-stationary series of degree one.\n",
    "\n",
    "### Traditional Time Series Models\n",
    "\n",
    "There are many ways to model a time series for forecasting. Most time series models aim to incorporate the trend, seasonality, and remainder components, while also addressing the autocorrelation and stationarity embedded in the time series. For example, the autoregressive (AR) model discussed earlier addresses autocorrelation in a time series.\n",
    "\n",
    "One of the most widely used models in time series forecasting is the ARIMA model.\n",
    "\n",
    "#### ARIMA\n",
    "\n",
    "If we combine stationarity with autoregression and a moving average model, we will obtain an *ARIMA* model, which is an acronym for AutoRegressive Integrated Moving Average, and has the following components:\n",
    "\n",
    "*AR(p)*\n",
    "- represents autoregression, that is, the regression of the time series on itself, as we saw earlier, with an assumption that the current values ​​of the series depend on their previous values ​​with some interval (or several). The maximum interval in the model is referred to as *p*.\n",
    "\n",
    "*I(d)*\n",
    "- represents the order of integration. It is simply the number of differences needed to transform the series into stationary.\n",
    "\n",
    "*MA(q)*\n",
    "- represents the moving average Without going into details, it models the error of the time series; again, the assumption is that the current error depends on the previous one with some interval, which is referred to as *q*.\n",
    "\n",
    "The moving average equation is expressed as:\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232be475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
