{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8b22fa",
   "metadata": {},
   "source": [
    "Regarding the platforms used for machine learning, there are many algorithms and programming languages. However, the Python ecosystem is one of the most dominant and fastest growing in machine learning.\n",
    "\n",
    "Given its popularity and high adoption rate, we will use Python as our main programming language. First, we will look at the details of the Python packages used for machine learning, followed by the model development steps in the Python framework.\n",
    "\n",
    "## Why Python?\n",
    "\n",
    "These are some of the reasons for Python's popularity:\n",
    "\n",
    "- high-level syntax (compared to lower-level languages ​​like C, Java, and C++). Applications can be developed by writing fewer lines of code, making Python attractive to both beginners and advanced programmers;\n",
    "- efficient development life cycle;\n",
    "- large collection of community-run and open-source libraries;\n",
    "- strong portability.\n",
    "\n",
    "Python's simplicity attracts many developers who create new libraries for machine learning, leading to its strong adoption.\n",
    "\n",
    "## Python Libs for Machine Learning\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data Manipulation and Transformation**\n",
    "\n",
    "*NumPy* (https://numpy.org)\n",
    "\n",
    "    - provides support for large and multidimensional arrays, as well as an extensive collection of mathematical functions;\n",
    "\n",
    "*Pandas* (https://pandas.pydata.org)\n",
    "\n",
    "    - a library for data manipulation and analysis. Among other features, it offers data structure to work with tables and tools to manipulate them;\n",
    "    \n",
    "<br>\n",
    "\n",
    "**Machine Learning and Statistical Analysis**\n",
    "\n",
    "*SciPy* (https://www.scipy.org)\n",
    "\n",
    "    - the combination of **NumPy**, **Pandas** and **Matplotlib** is commonly known as **SciPy**, which is an ecosystem of Python libraries for mathematics, science and engineering;\n",
    "    \n",
    "*Scikit-learn* (https://scikit-learn.org)\n",
    "\n",
    "    - a machine learning library offering a wide range of algorithms and utilities;\n",
    "    \n",
    "*StatsModels* (https://www.statsmodels.org)\n",
    "\n",
    "    - a Python module that provides classes and functions for estimating numerous statistical models, as well as for conducting statistical tests and exploring statistical data;\n",
    "    \n",
    "*TensorFlow* (https://www.tensorflow.org) and *Theano* (https://deeplearning.net/software/theano)\n",
    "\n",
    "    - dataflow libraries that facilitate work with neural networks;\n",
    "    \n",
    "*Keras* (https://keras.io)\n",
    "\n",
    "    - a library of artificial neural networks that can act as a simplified interface for the **TensorFlow*/Theano* packages;\n",
    "    \n",
    "<br>\n",
    "\n",
    "**Data Visualization**\n",
    "\n",
    "*Matplotlib* (https://matplotlib.org)\n",
    "\n",
    "    - a plotting library that allows you to create 2D graphs and plots;\n",
    "\n",
    "*Seaborn* (https://seaborn.pydata.org)\n",
    "\n",
    "    - a data visualization library based on Matplotlib. Provides a high-level interface for creating attractive and informative statistical graphs;\n",
    "    \n",
    "<br>\n",
    "\n",
    "## Machine Learning Crisp-DM Model\n",
    "\n",
    "The figure below shows a general idea of a simple machine learning template in seven steps, which can be used to start any machine learning model in Python.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1024/1*sicHaDLyHRGuJm9eZTaHNw.png\" width=\"600\">\n",
    "    <figcaption>Step by step to develop a machine learning model</figcaption>\n",
    "</figure>\n",
    "\n",
    "### Blueprint de Desenvolvimento de Modelo\n",
    "\n",
    "Now we will detail each step of the model development process:\n",
    "\n",
    "**1. Problem definition**\n",
    "The first step in any project is defining the problem. Powerful algorithms can be used to solve it, but the results will be of no use if the wrong problem is solved.\n",
    "The following framework should be used to define the problem:\n",
    "\n",
    "    1. describe the problem informally and formally. List similar assumptions and problems;\n",
    "    2. list the motivation for solving the problem, the benefits brought by the resolution and how it will be used;\n",
    "    3. describe how the problem would be solved using domain knowledge.\n",
    "\n",
    "\n",
    "**2. Loading data and libs**\n",
    "The second step gives you everything you need to start working on the problem. This includes loading libraries, packages, and functions required for model development.\n",
    "\n",
    "**2.1. Loading the libs**\n",
    "```Python\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "```\n",
    "Details of libraries and modules for specific functionalities can be found on each page.\n",
    "\n",
    "**2.2. Loading data**\n",
    "The following items must be checked and removed before data is loaded:\n",
    "\n",
    "    - column headers;\n",
    "    - comments or characters;\n",
    "    - delimiter.\n",
    "\n",
    "There are many ways to load data. Some of the most common are:\n",
    "\n",
    "```Python\n",
    "# Upload CSV files with Pandas\n",
    "from pandas import read_csv\n",
    "filename = 'xpto.csv'\n",
    "data = read_csv(filename, names=names)\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Upload files from a URL\n",
    "url = 'https://goo.glvhm1eU'\n",
    "names = ['age', 'class']\n",
    "data = read_csv(url, names=names)\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Load files using pandas_darareader\n",
    "import pandas_datareader.data as web\n",
    "ccy_tickers = ['DEXJPUS', 'DEXUSUK']\n",
    "idx_tickers = ['SP500', 'DJIA', 'VIXCLS']\n",
    "\n",
    "stk_data = web.DataReader(stk_tickers, 'yahoo')\n",
    "ccy_data = web.DataReader(ccy_tickers, 'fred')\n",
    "idx_data = web.DataReader(idx_tickers, 'fred')\n",
    "```\n",
    "\n",
    "**3. Exploratory data analysis**\n",
    "In this step, we analyze the data set.\n",
    "\n",
    "**3.1. Descriptive statistics**\n",
    "Understanding the dataset is one of the most important processes in model development. The steps to do this include:\n",
    "\n",
    "    1. view the raw data;\n",
    "    2. evaluate the dimensions of the set;\n",
    "    3. evaluate the types of data attributes;\n",
    "    4. summarize the distribution, descriptive statistics, and relationship between variables in the data set.\n",
    "    \n",
    "These steps are demonstrated below:\n",
    "\n",
    "```Python\n",
    "# View data\n",
    "set_option('display.width', 100)\n",
    "dataset.head(1)\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Evaluate dataset dimensions\n",
    "dataset.shape\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Evaluate data attribute types\n",
    "set_option('display.max_rows', 500)\n",
    "dataset.dtypes\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Summarize data using descriptive statistics\n",
    "set_option('precision', 3)\n",
    "dataset.describe()\n",
    "```\n",
    "\n",
    "**3.2. Data visualization**\n",
    "The quickest way to learn more about data is to visualize it. Visualization involves independently understanding each attribute of the dataset.\n",
    "\n",
    "Types of charts:\n",
    "\n",
    "*Univariates*\n",
    "- histograms and density graphs;\n",
    "\n",
    "*Multivariates*\n",
    "- correlation matrix and scatter plot;\n",
    "\n",
    "Below are Python code examples for univariate graph types:\n",
    "\n",
    "```Python\n",
    "# Univariate: histogram\n",
    "from matplotlib import pyplot\n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(10,4))\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Univariate: density plot\n",
    "from matplotlib import pyplot\n",
    "dataset.plot(kind='density', subplots=True, layout=(3, 3), sharex=False, legend=True, fontsize=1, figsize=(10,4))\n",
    "pyplot.show()\n",
    "```\n",
    "\n",
    "Below are Python code examples for multivariate graph types:\n",
    "\n",
    "```Python\n",
    "# Multivariate: correlation matrix\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "correlation = dataset.corr()\n",
    "pyplot.figure(figsize=(5,5))\n",
    "pyplot.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True, annot=True, cmap='cubehelix')\n",
    "```\n",
    "\n",
    "```Python\n",
    "# Multivariate: scatter plot\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(dataset)\n",
    "```\n",
    "\n",
    "**4. Data preparation**\n",
    "Data preparation is the preprocessing step in which data from one or more sources is cleaned and transformed to improve its quality before it is used.\n",
    "\n",
    "**4.1. Data cleaning**\n",
    "In machine learning modeling, bad data can be costly. Data cleansing involves checking the following:\n",
    "\n",
    "*Validity*\n",
    "- type, range, ...;\n",
    "\n",
    "*Accuracy*\n",
    "- the degree to which the data are close to true values;\n",
    "\n",
    "*Completeness*\n",
    "- the degree to which all necessary data are known;\n",
    "\n",
    "*Uniformity*\n",
    "- the degree to which data are specified using the same unit of measurement;\n",
    "\n",
    "Different options for cleaning data include:\n",
    "\n",
    "*Remove \"NA\" values ​​from data*\n",
    "```Python\n",
    "dataset.dropna(axis=0)\n",
    "```\n",
    "\n",
    "*Fill \"NA\" with 0*\n",
    "```Python\n",
    "dataset.fillna(0)\n",
    "```\n",
    "\n",
    "*Fill in \"NA\" with the column average*\n",
    "```Python\n",
    "dataset['col'] = dataset['col'].fillna(dataset['col'].mean())\n",
    "```\n",
    "\n",
    "**4.2. Feature selection**\n",
    "The features of the data used to train machine learning models have a huge influence on performance. Irrelevant or partially relevant features can negatively impact model performance. Feature selection is a process in which the features in the data that contribute most to the prediction of the variable or output are automatically selected.\n",
    "\n",
    "The benefits of performing feature selection before modeling are:\n",
    "\n",
    "*Reduced overfitting (overfitting)*\n",
    "- less redundant data means fewer opportunities for the model to make decisions based on noise;\n",
    "\n",
    "*Improves performance*\n",
    "- less misleading data means better modeling performance;\n",
    "\n",
    "*Reduction in training time and memory volume*\n",
    "- less data means faster training and less memory volume;\n",
    "\n",
    "The following sample feature is an example that demonstrates when two best features are selected using the *SelectKBest* function in **sklearn**. This function ranks the features using an underlying function and then removes all but the highest ranked *k* feature:\n",
    "\n",
    "```Python\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "bestfeatures = SelectKBest(k=5)\n",
    "dfscores = pd.DataFrame(X.fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns) \n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "print(featureScores.nlargest(2,'Score'))\n",
    "```\n",
    "\n",
    "When features are irrelevant, they should be removed. This is presented below:\n",
    "\n",
    "```Python\n",
    "# Removing old features\n",
    "dataset.drop(['Feature1', 'Feature2', 'Feature3'], axis=1, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de659b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
